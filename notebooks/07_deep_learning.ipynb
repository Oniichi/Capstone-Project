{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6790c021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e8dd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5469, 43)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "gold",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eurusd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "treasury_10y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "spy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vix",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dxy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "oil",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "target",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gold_lag1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gold_lag2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gold_lag3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gold_lag4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gold_lag5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vol_10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vol_20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vol_30",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ma_10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ma_20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ma_30",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "momentum_10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "momentum_20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "momentum_30",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rsi_14",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "macd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "macd_signal",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eurusd_lag1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eurusd_lag2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eurusd_lag3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "spy_lag1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "spy_lag2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "spy_lag3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vix_lag1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vix_lag2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vix_lag3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dxy_lag1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dxy_lag2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dxy_lag3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "oil_lag1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "oil_lag2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "oil_lag3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "treasury_10y_lag1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "treasury_10y_lag2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "treasury_10y_lag3",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2a4de21d-f625-4af9-83b9-f65f1a3b0bd6",
       "rows": [
        [
         "2004-01-13 00:00:00",
         "-0.0060989342256327",
         "0.0035290394908482",
         "4.0279998779296875",
         "-0.0058295394692082",
         "0.072532773058167",
         "-0.0004675735137396",
         "-0.0083525606374236",
         "-0.0047203208458317",
         "-0.0002345358934032",
         "0.0056603629634064",
         "0.0049774973545766",
         "-0.0021286516614683",
         "-0.0037700427109477",
         "0.0076885153648309",
         "0.0060846711753157",
         "0.0057852477631346",
         "0.0016455861186227",
         "0.0019440026493882",
         "0.001629153045355",
         "0.0164558611862277",
         "0.0388800529877648",
         "0.0488745913606505",
         "44.729371070708645",
         "-0.0002829471434768",
         "0.0003654214250887",
         "-0.0091735787877978",
         "0.0065709376563893",
         "0.0106031736152272",
         "0.007385176505688",
         "-0.0087315688691104",
         "0.0039847560185755",
         "0.0041790862581623",
         "0.0730301325045266",
         "0.0070967520436933",
         "0.0051698089325677",
         "-0.0053757051082528",
         "-0.0073085530826206",
         "0.0119498639172681",
         "0.0097116490729938",
         "0.0107079304517807",
         "4.083000183105469",
         "4.085999965667725",
         "4.249000072479248"
        ],
        [
         "2004-01-14 00:00:00",
         "-0.0047203208458317",
         "-0.0105510063201985",
         "3.986000061035156",
         "0.0083508697401186",
         "-0.0715078076529928",
         "0.0060811206885245",
         "0.0020331017776289",
         "-0.0315390512818324",
         "-0.0060989342256327",
         "-0.0002345358934032",
         "0.0056603629634064",
         "0.0049774973545766",
         "-0.0021286516614683",
         "0.0078297080588691",
         "0.00590356469669",
         "0.0058977705790362",
         "0.0014613884564481",
         "0.0011806395793529",
         "0.0014552966165821",
         "0.0146138845644811",
         "0.0236127915870599",
         "0.0436588984974641",
         "47.25815115483868",
         "-0.0007348581699757",
         "0.0001453655060758",
         "0.0035290394908482",
         "-0.0091735787877978",
         "0.0065709376563893",
         "-0.0058295394692082",
         "0.007385176505688",
         "-0.0087315688691104",
         "0.072532773058167",
         "0.0041790862581623",
         "0.0730301325045266",
         "-0.0004675735137396",
         "0.0051698089325677",
         "-0.0053757051082528",
         "-0.0083525606374236",
         "0.0119498639172681",
         "0.0097116490729938",
         "4.0279998779296875",
         "4.083000183105469",
         "4.085999965667725"
        ],
        [
         "2004-01-15 00:00:00",
         "-0.0315390512818324",
         "-0.0039566750210084",
         "3.9709999561309814",
         "0.0024675565551355",
         "-0.0710447510676597",
         "0.0061606275347805",
         "-0.030724677486696",
         "-0.0041625409276669",
         "-0.0047203208458317",
         "-0.0060989342256327",
         "-0.0002345358934032",
         "0.0056603629634064",
         "0.0049774973545766",
         "0.0130773814304934",
         "0.009372076548075",
         "0.0084253284496538",
         "-0.0016925166717351",
         "-0.0002021374867391",
         "0.0004535126188806",
         "-0.0169251667173512",
         "-0.004042749734783",
         "0.0136053785664181",
         "36.03204564732906",
         "-0.0032199309671704",
         "-0.0005276937885733",
         "-0.0105510063201985",
         "0.0035290394908482",
         "-0.0091735787877978",
         "0.0083508697401186",
         "-0.0058295394692082",
         "0.007385176505688",
         "-0.0715078076529928",
         "0.072532773058167",
         "0.0041790862581623",
         "0.0060811206885245",
         "-0.0004675735137396",
         "0.0051698089325677",
         "0.0020331017776289",
         "-0.0083525606374236",
         "0.0119498639172681",
         "3.986000061035156",
         "4.0279998779296875",
         "4.083000183105469"
        ],
        [
         "2004-01-16 00:00:00",
         "-0.0041625409276669",
         "-0.0161050762616106",
         "4.013999938964844",
         "0.0039549857831444",
         "-0.0359897432207456",
         "0.013516703227121",
         "0.0487440530817884",
         "0.0",
         "-0.0315390512818324",
         "-0.0047203208458317",
         "-0.0060989342256327",
         "-0.0002345358934032",
         "0.0056603629634064",
         "0.0130837680528664",
         "0.009395072840499",
         "0.0083519746481742",
         "-0.0021087707645018",
         "-0.000264067931356",
         "5.854122013076969e-05",
         "-0.0210877076450181",
         "-0.0052813586271201",
         "0.001756236603923",
         "46.190290575577464",
         "-0.0029463497860969",
         "-0.0010114249880781",
         "-0.0039566750210084",
         "-0.0105510063201985",
         "0.0035290394908482",
         "0.0024675565551355",
         "0.0083508697401186",
         "-0.0058295394692082",
         "-0.0710447510676597",
         "-0.0715078076529928",
         "0.072532773058167",
         "0.0061606275347805",
         "0.0060811206885245",
         "-0.0004675735137396",
         "-0.030724677486696",
         "0.0020331017776289",
         "-0.0083525606374236",
         "3.9709999561309814",
         "3.986000061035156",
         "4.0279998779296875"
        ],
        [
         "2004-01-19 00:00:00",
         "0.0",
         "-0.0035455987557183",
         "4.013999938964844",
         "0.0",
         "0.0",
         "-0.0007978991467653",
         "0.0",
         "0.0147528886646448",
         "-0.0041625409276669",
         "-0.0315390512818324",
         "-0.0047203208458317",
         "-0.0060989342256327",
         "-0.0002345358934032",
         "0.0103847925946379",
         "0.0093555023212276",
         "0.0083515769036345",
         "-0.0042016217228799",
         "-0.0004351326741126",
         "4.2136019176446365e-05",
         "-0.0420162172287999",
         "-0.0087026534822531",
         "0.0012640805752933",
         "48.15731166964136",
         "-0.0023663743732358",
         "-0.0012824148651096",
         "-0.0161050762616106",
         "-0.0039566750210084",
         "-0.0105510063201985",
         "0.0039549857831444",
         "0.0024675565551355",
         "0.0083508697401186",
         "-0.0359897432207456",
         "-0.0710447510676597",
         "-0.0715078076529928",
         "0.013516703227121",
         "0.0061606275347805",
         "0.0060811206885245",
         "0.0487440530817884",
         "-0.030724677486696",
         "0.0020331017776289",
         "4.013999938964844",
         "3.9709999561309814",
         "3.986000061035156"
        ]
       ],
       "shape": {
        "columns": 43,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold</th>\n",
       "      <th>eurusd</th>\n",
       "      <th>treasury_10y</th>\n",
       "      <th>spy</th>\n",
       "      <th>vix</th>\n",
       "      <th>dxy</th>\n",
       "      <th>oil</th>\n",
       "      <th>target</th>\n",
       "      <th>gold_lag1</th>\n",
       "      <th>gold_lag2</th>\n",
       "      <th>...</th>\n",
       "      <th>vix_lag3</th>\n",
       "      <th>dxy_lag1</th>\n",
       "      <th>dxy_lag2</th>\n",
       "      <th>dxy_lag3</th>\n",
       "      <th>oil_lag1</th>\n",
       "      <th>oil_lag2</th>\n",
       "      <th>oil_lag3</th>\n",
       "      <th>treasury_10y_lag1</th>\n",
       "      <th>treasury_10y_lag2</th>\n",
       "      <th>treasury_10y_lag3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-13</th>\n",
       "      <td>-0.006099</td>\n",
       "      <td>0.003529</td>\n",
       "      <td>4.028</td>\n",
       "      <td>-0.005830</td>\n",
       "      <td>0.072533</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>-0.008353</td>\n",
       "      <td>-0.004720</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007097</td>\n",
       "      <td>0.005170</td>\n",
       "      <td>-0.005376</td>\n",
       "      <td>-0.007309</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.009712</td>\n",
       "      <td>0.010708</td>\n",
       "      <td>4.083</td>\n",
       "      <td>4.086</td>\n",
       "      <td>4.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-14</th>\n",
       "      <td>-0.004720</td>\n",
       "      <td>-0.010551</td>\n",
       "      <td>3.986</td>\n",
       "      <td>0.008351</td>\n",
       "      <td>-0.071508</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>-0.031539</td>\n",
       "      <td>-0.006099</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073030</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>0.005170</td>\n",
       "      <td>-0.005376</td>\n",
       "      <td>-0.008353</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.009712</td>\n",
       "      <td>4.028</td>\n",
       "      <td>4.083</td>\n",
       "      <td>4.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-15</th>\n",
       "      <td>-0.031539</td>\n",
       "      <td>-0.003957</td>\n",
       "      <td>3.971</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>-0.071045</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>-0.030725</td>\n",
       "      <td>-0.004163</td>\n",
       "      <td>-0.004720</td>\n",
       "      <td>-0.006099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>0.005170</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>-0.008353</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>3.986</td>\n",
       "      <td>4.028</td>\n",
       "      <td>4.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-16</th>\n",
       "      <td>-0.004163</td>\n",
       "      <td>-0.016105</td>\n",
       "      <td>4.014</td>\n",
       "      <td>0.003955</td>\n",
       "      <td>-0.035990</td>\n",
       "      <td>0.013517</td>\n",
       "      <td>0.048744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.031539</td>\n",
       "      <td>-0.004720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072533</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>-0.030725</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>-0.008353</td>\n",
       "      <td>3.971</td>\n",
       "      <td>3.986</td>\n",
       "      <td>4.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003546</td>\n",
       "      <td>4.014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014753</td>\n",
       "      <td>-0.004163</td>\n",
       "      <td>-0.031539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071508</td>\n",
       "      <td>0.013517</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.048744</td>\n",
       "      <td>-0.030725</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>4.014</td>\n",
       "      <td>3.971</td>\n",
       "      <td>3.986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                gold    eurusd  treasury_10y       spy       vix       dxy  \\\n",
       "Date                                                                         \n",
       "2004-01-13 -0.006099  0.003529         4.028 -0.005830  0.072533 -0.000468   \n",
       "2004-01-14 -0.004720 -0.010551         3.986  0.008351 -0.071508  0.006081   \n",
       "2004-01-15 -0.031539 -0.003957         3.971  0.002468 -0.071045  0.006161   \n",
       "2004-01-16 -0.004163 -0.016105         4.014  0.003955 -0.035990  0.013517   \n",
       "2004-01-19  0.000000 -0.003546         4.014  0.000000  0.000000 -0.000798   \n",
       "\n",
       "                 oil    target  gold_lag1  gold_lag2  ...  vix_lag3  dxy_lag1  \\\n",
       "Date                                                  ...                       \n",
       "2004-01-13 -0.008353 -0.004720  -0.000235   0.005660  ...  0.007097  0.005170   \n",
       "2004-01-14  0.002033 -0.031539  -0.006099  -0.000235  ...  0.073030 -0.000468   \n",
       "2004-01-15 -0.030725 -0.004163  -0.004720  -0.006099  ...  0.004179  0.006081   \n",
       "2004-01-16  0.048744  0.000000  -0.031539  -0.004720  ...  0.072533  0.006161   \n",
       "2004-01-19  0.000000  0.014753  -0.004163  -0.031539  ... -0.071508  0.013517   \n",
       "\n",
       "            dxy_lag2  dxy_lag3  oil_lag1  oil_lag2  oil_lag3  \\\n",
       "Date                                                           \n",
       "2004-01-13 -0.005376 -0.007309  0.011950  0.009712  0.010708   \n",
       "2004-01-14  0.005170 -0.005376 -0.008353  0.011950  0.009712   \n",
       "2004-01-15 -0.000468  0.005170  0.002033 -0.008353  0.011950   \n",
       "2004-01-16  0.006081 -0.000468 -0.030725  0.002033 -0.008353   \n",
       "2004-01-19  0.006161  0.006081  0.048744 -0.030725  0.002033   \n",
       "\n",
       "            treasury_10y_lag1  treasury_10y_lag2  treasury_10y_lag3  \n",
       "Date                                                                 \n",
       "2004-01-13              4.083              4.086              4.249  \n",
       "2004-01-14              4.028              4.083              4.086  \n",
       "2004-01-15              3.986              4.028              4.083  \n",
       "2004-01-16              3.971              3.986              4.028  \n",
       "2004-01-19              4.014              3.971              3.986  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/erion/Desktop/MSCF2/ADA/Capstone-Project/data/processed/modeling_dataset.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5d874f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 3123\n",
      "Test samples: 261\n"
     ]
    }
   ],
   "source": [
    "train = df.loc[:'2015-12-31'].copy()\n",
    "test  = df.loc['2016-01-01':'2016-12-31'].copy()\n",
    "\n",
    "X_train = train.drop(columns=['target'])\n",
    "y_train = train['target']\n",
    "\n",
    "X_test = test.drop(columns=['target'])\n",
    "y_test = test['target']\n",
    "\n",
    "print(\"Train samples:\", len(X_train))\n",
    "print(\"Test samples:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b625518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dcc4c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/goldcapstone/lib/python3.10/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,752</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,752\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,865</span> (19.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,865\u001b[0m (19.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,865</span> (19.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,865\u001b[0m (19.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output: predicted return\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse'\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc7b9c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2453 - val_loss: 0.0518\n",
      "Epoch 2/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 0.0473 - val_loss: 0.0322\n",
      "Epoch 3/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.0278 - val_loss: 0.0235\n",
      "Epoch 4/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 0.0189 - val_loss: 0.0194\n",
      "Epoch 5/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.0141 - val_loss: 0.0168\n",
      "Epoch 6/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.0114 - val_loss: 0.0145\n",
      "Epoch 7/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.0091 - val_loss: 0.0127\n",
      "Epoch 8/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.0074 - val_loss: 0.0117\n",
      "Epoch 9/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.0063 - val_loss: 0.0108\n",
      "Epoch 10/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.0054 - val_loss: 0.0102\n",
      "Epoch 11/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.0048 - val_loss: 0.0096\n",
      "Epoch 12/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 0.0042 - val_loss: 0.0089\n",
      "Epoch 13/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - loss: 0.0038 - val_loss: 0.0084\n",
      "Epoch 14/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 0.0034 - val_loss: 0.0079\n",
      "Epoch 15/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 0.0034 - val_loss: 0.0074\n",
      "Epoch 16/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 0.0028 - val_loss: 0.0071\n",
      "Epoch 17/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 0.0025 - val_loss: 0.0069\n",
      "Epoch 18/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.0023 - val_loss: 0.0064\n",
      "Epoch 19/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - loss: 0.0021 - val_loss: 0.0060\n",
      "Epoch 20/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 21/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 22/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 23/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 - val_loss: 0.0053\n",
      "Epoch 24/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 25/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 26/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 27/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 28/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.0011 - val_loss: 0.0049\n",
      "Epoch 29/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 30/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 9.9540e-04 - val_loss: 0.0044\n",
      "Epoch 31/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 9.2848e-04 - val_loss: 0.0042\n",
      "Epoch 32/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 9.0168e-04 - val_loss: 0.0041\n",
      "Epoch 33/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 8.9258e-04 - val_loss: 0.0042\n",
      "Epoch 34/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 8.5941e-04 - val_loss: 0.0039\n",
      "Epoch 35/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 7.7657e-04 - val_loss: 0.0040\n",
      "Epoch 36/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 7.4468e-04 - val_loss: 0.0038\n",
      "Epoch 37/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 6.8181e-04 - val_loss: 0.0039\n",
      "Epoch 38/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 6.5759e-04 - val_loss: 0.0036\n",
      "Epoch 39/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 6.4930e-04 - val_loss: 0.0036\n",
      "Epoch 40/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 6.0257e-04 - val_loss: 0.0037\n",
      "Epoch 41/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 6.2164e-04 - val_loss: 0.0035\n",
      "Epoch 42/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.6116e-04 - val_loss: 0.0033\n",
      "Epoch 43/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 5.5282e-04 - val_loss: 0.0033\n",
      "Epoch 44/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 5.5746e-04 - val_loss: 0.0032\n",
      "Epoch 45/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 4.9531e-04 - val_loss: 0.0031\n",
      "Epoch 46/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 5.0876e-04 - val_loss: 0.0032\n",
      "Epoch 47/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 5.7587e-04 - val_loss: 0.0030\n",
      "Epoch 48/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 5.5614e-04 - val_loss: 0.0030\n",
      "Epoch 49/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - loss: 5.2766e-04 - val_loss: 0.0027\n",
      "Epoch 50/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 5.5383e-04 - val_loss: 0.0030\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0c9f061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "MLP Performance\n",
      "---------------------------\n",
      "RMSE: 0.051043\n",
      "MAE:  0.039661\n",
      "Directional Accuracy: 47.89%\n"
     ]
    }
   ],
   "source": [
    "mlp_pred = model.predict(X_test_scaled).flatten()\n",
    "\n",
    "rmse_mlp = np.sqrt(mean_squared_error(y_test, mlp_pred))\n",
    "mae_mlp = mean_absolute_error(y_test, mlp_pred)\n",
    "dir_acc_mlp = (np.sign(mlp_pred) == np.sign(y_test)).mean() * 100\n",
    "\n",
    "print(\"MLP Performance\")\n",
    "print(\"---------------------------\")\n",
    "print(f\"RMSE: {rmse_mlp:.6f}\")\n",
    "print(f\"MAE:  {mae_mlp:.6f}\")\n",
    "print(f\"Directional Accuracy: {dir_acc_mlp:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed6972a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM train shape: (3118, 5, 42)\n",
      "LSTM test shape: (256, 5, 42)\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(X, y, timesteps=5):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - timesteps):\n",
    "        X_seq.append(X[i:i+timesteps])\n",
    "        y_seq.append(y[i+timesteps])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Convert scaled features to sequences\n",
    "timesteps = 5\n",
    "\n",
    "X_train_lstm, y_train_lstm = create_sequences(X_train_scaled, y_train.values, timesteps)\n",
    "X_test_lstm, y_test_lstm   = create_sequences(X_test_scaled, y_test.values, timesteps)\n",
    "\n",
    "print(\"LSTM train shape:\", X_train_lstm.shape)\n",
    "print(\"LSTM test shape:\", X_test_lstm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31d59e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/goldcapstone/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">27,392</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m27,392\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,505</span> (115.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,505\u001b[0m (115.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,505</span> (115.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,505\u001b[0m (115.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "lstm_model = Sequential([\n",
    "    LSTM(64, activation='tanh', return_sequences=False, input_shape=(timesteps, X_train_lstm.shape[2])),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "lstm_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse'\n",
    ")\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bb6538c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0106 - val_loss: 0.0030\n",
      "Epoch 2/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 3/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 4/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4353e-04 - val_loss: 0.0021\n",
      "Epoch 5/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4729e-04 - val_loss: 0.0016\n",
      "Epoch 6/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2073e-04 - val_loss: 0.0015\n",
      "Epoch 7/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4692e-04 - val_loss: 0.0014\n",
      "Epoch 8/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7730e-04 - val_loss: 0.0016\n",
      "Epoch 9/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6858e-04 - val_loss: 0.0013\n",
      "Epoch 10/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7504e-04 - val_loss: 0.0014\n",
      "Epoch 11/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7692e-04 - val_loss: 0.0014\n",
      "Epoch 12/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.6182e-04 - val_loss: 0.0012\n",
      "Epoch 13/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3902e-04 - val_loss: 0.0013\n",
      "Epoch 14/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7532e-04 - val_loss: 0.0013\n",
      "Epoch 15/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8788e-04 - val_loss: 0.0012\n",
      "Epoch 16/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4390e-04 - val_loss: 0.0011\n",
      "Epoch 17/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1017e-04 - val_loss: 0.0011\n",
      "Epoch 18/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7380e-04 - val_loss: 0.0010\n",
      "Epoch 19/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4871e-04 - val_loss: 0.0012\n",
      "Epoch 20/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3198e-04 - val_loss: 0.0010\n",
      "Epoch 21/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0700e-04 - val_loss: 0.0010\n",
      "Epoch 22/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7849e-05 - val_loss: 0.0010\n",
      "Epoch 23/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2911e-05 - val_loss: 0.0010\n",
      "Epoch 24/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2604e-05 - val_loss: 9.5091e-04\n",
      "Epoch 25/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3577e-05 - val_loss: 9.8286e-04\n",
      "Epoch 26/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4051e-05 - val_loss: 9.1761e-04\n",
      "Epoch 27/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1147e-04 - val_loss: 9.5626e-04\n",
      "Epoch 28/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1748e-04 - val_loss: 9.8336e-04\n",
      "Epoch 29/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3285e-04 - val_loss: 9.5069e-04\n",
      "Epoch 30/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2467e-04 - val_loss: 0.0010\n",
      "Epoch 31/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0827e-04 - val_loss: 8.6089e-04\n",
      "Epoch 32/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0787e-04 - val_loss: 8.2448e-04\n",
      "Epoch 33/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1491e-04 - val_loss: 8.0230e-04\n",
      "Epoch 34/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1067e-04 - val_loss: 9.2545e-04\n",
      "Epoch 35/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0170e-04 - val_loss: 8.3294e-04\n",
      "Epoch 36/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.5081e-05 - val_loss: 7.8651e-04\n",
      "Epoch 37/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0100e-04 - val_loss: 7.6156e-04\n",
      "Epoch 38/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5105e-05 - val_loss: 7.6094e-04\n",
      "Epoch 39/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5728e-05 - val_loss: 7.8663e-04\n",
      "Epoch 40/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3650e-05 - val_loss: 6.9649e-04\n"
     ]
    }
   ],
   "source": [
    "history_lstm = lstm_model.fit(\n",
    "    X_train_lstm, y_train_lstm,\n",
    "    validation_split=0.2,\n",
    "    epochs=40,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5af1e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "LSTM Performance\n",
      "---------------------------\n",
      "RMSE: 0.029928\n",
      "MAE:  0.024555\n",
      "Directional Accuracy: 42.97%\n"
     ]
    }
   ],
   "source": [
    "lstm_pred = lstm_model.predict(X_test_lstm).flatten()\n",
    "\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_test_lstm, lstm_pred))\n",
    "mae_lstm = mean_absolute_error(y_test_lstm, lstm_pred)\n",
    "dir_acc_lstm = (np.sign(lstm_pred) == np.sign(y_test_lstm)).mean() * 100\n",
    "\n",
    "print(\"LSTM Performance\")\n",
    "print(\"---------------------------\")\n",
    "print(f\"RMSE: {rmse_lstm:.6f}\")\n",
    "print(f\"MAE:  {mae_lstm:.6f}\")\n",
    "print(f\"Directional Accuracy: {dir_acc_lstm:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec4209d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/goldcapstone/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,736</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m20,736\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,849</span> (89.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,849\u001b[0m (89.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,849</span> (89.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,849\u001b[0m (89.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "gru_model = Sequential([\n",
    "    GRU(64, activation='tanh', return_sequences=False, input_shape=(timesteps, X_train_lstm.shape[2])),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "gru_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse'\n",
    ")\n",
    "\n",
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8efdce6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0217 - val_loss: 0.0049\n",
      "Epoch 2/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 3/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 4/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 5/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 6/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4398e-04 - val_loss: 0.0020\n",
      "Epoch 7/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7689e-04 - val_loss: 0.0018\n",
      "Epoch 8/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4055e-04 - val_loss: 0.0018\n",
      "Epoch 9/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6063e-04 - val_loss: 0.0016\n",
      "Epoch 10/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0195e-04 - val_loss: 0.0015\n",
      "Epoch 11/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9149e-04 - val_loss: 0.0013\n",
      "Epoch 12/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6918e-04 - val_loss: 0.0013\n",
      "Epoch 13/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4710e-04 - val_loss: 0.0012\n",
      "Epoch 14/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5456e-04 - val_loss: 0.0012\n",
      "Epoch 15/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5415e-04 - val_loss: 0.0011\n",
      "Epoch 16/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4258e-04 - val_loss: 0.0010\n",
      "Epoch 17/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1713e-04 - val_loss: 0.0010\n",
      "Epoch 18/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1003e-04 - val_loss: 9.4056e-04\n",
      "Epoch 19/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8835e-04 - val_loss: 9.1890e-04\n",
      "Epoch 20/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8594e-04 - val_loss: 9.2945e-04\n",
      "Epoch 21/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3876e-04 - val_loss: 8.7739e-04\n",
      "Epoch 22/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0465e-04 - val_loss: 8.3790e-04\n",
      "Epoch 23/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9754e-04 - val_loss: 8.6936e-04\n",
      "Epoch 24/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9761e-04 - val_loss: 8.0245e-04\n",
      "Epoch 25/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7564e-04 - val_loss: 7.9820e-04\n",
      "Epoch 26/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4548e-04 - val_loss: 7.9941e-04\n",
      "Epoch 27/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3146e-04 - val_loss: 7.9949e-04\n",
      "Epoch 28/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3287e-04 - val_loss: 7.7906e-04\n",
      "Epoch 29/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2869e-04 - val_loss: 8.0085e-04\n",
      "Epoch 30/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3987e-04 - val_loss: 7.9363e-04\n",
      "Epoch 31/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5071e-04 - val_loss: 7.5701e-04\n",
      "Epoch 32/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0263e-04 - val_loss: 7.3844e-04\n",
      "Epoch 33/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1714e-04 - val_loss: 7.1792e-04\n",
      "Epoch 34/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.6993e-04 - val_loss: 7.1747e-04\n",
      "Epoch 35/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2257e-04 - val_loss: 6.9713e-04\n",
      "Epoch 36/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0010e-04 - val_loss: 6.2814e-04\n",
      "Epoch 37/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8428e-04 - val_loss: 6.2512e-04\n",
      "Epoch 38/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7599e-04 - val_loss: 6.1694e-04\n",
      "Epoch 39/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7348e-04 - val_loss: 5.7324e-04\n",
      "Epoch 40/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5372e-04 - val_loss: 5.5840e-04\n"
     ]
    }
   ],
   "source": [
    "history_gru = gru_model.fit(\n",
    "    X_train_lstm, y_train_lstm,\n",
    "    validation_split=0.2,\n",
    "    epochs=40,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21fbb0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "GRU Performance\n",
      "---------------------------\n",
      "RMSE: 0.027986\n",
      "MAE:  0.021664\n",
      "Directional Accuracy: 42.19%\n"
     ]
    }
   ],
   "source": [
    "gru_pred = gru_model.predict(X_test_lstm).flatten()\n",
    "\n",
    "rmse_gru = np.sqrt(mean_squared_error(y_test_lstm, gru_pred))\n",
    "mae_gru = mean_absolute_error(y_test_lstm, gru_pred)\n",
    "dir_acc_gru = (np.sign(gru_pred) == np.sign(y_test_lstm)).mean() * 100\n",
    "\n",
    "print(\"GRU Performance\")\n",
    "print(\"---------------------------\")\n",
    "print(f\"RMSE: {rmse_gru:.6f}\")\n",
    "print(f\"MAE:  {mae_gru:.6f}\")\n",
    "print(f\"Directional Accuracy: {dir_acc_gru:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e1d43dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEEP LEARNING MODEL COMPARISON (2016 Test Set)\n",
      "  Model      RMSE       MAE  Directional Accuracy (%)\n",
      "0   MLP  0.051043  0.039661                  47.89272\n",
      "1  LSTM  0.029928  0.024555                  42.96875\n",
      "2   GRU  0.027986  0.021664                  42.18750\n"
     ]
    }
   ],
   "source": [
    "results_dl = pd.DataFrame({\n",
    "    'Model': ['MLP', 'LSTM', 'GRU'],\n",
    "    'RMSE': [rmse_mlp, rmse_lstm, rmse_gru],\n",
    "    'MAE': [mae_mlp, mae_lstm, mae_gru],\n",
    "    'Directional Accuracy (%)': [dir_acc_mlp, dir_acc_lstm, dir_acc_gru]\n",
    "})\n",
    "\n",
    "print(\"\\nDEEP LEARNING MODEL COMPARISON (2016 Test Set)\")\n",
    "print(results_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goldcapstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
