{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6790c021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8e8dd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5469, 43)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "gold",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eurusd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "treasury_10y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "spy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vix",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dxy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "oil",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "target",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gold_lag1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gold_lag2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gold_lag3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gold_lag4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gold_lag5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vol_10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vol_20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vol_30",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ma_10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ma_20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ma_30",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "momentum_10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "momentum_20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "momentum_30",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rsi_14",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "macd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "macd_signal",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eurusd_lag1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eurusd_lag2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eurusd_lag3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "spy_lag1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "spy_lag2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "spy_lag3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vix_lag1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vix_lag2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vix_lag3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dxy_lag1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dxy_lag2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dxy_lag3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "oil_lag1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "oil_lag2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "oil_lag3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "treasury_10y_lag1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "treasury_10y_lag2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "treasury_10y_lag3",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f24d95b0-d2c4-408a-a32f-51fd3b940d5c",
       "rows": [
        [
         "2004-01-13 00:00:00",
         "-0.0060989342256327",
         "0.0035290394908482",
         "4.0279998779296875",
         "-0.0058297419394889",
         "0.072532773058167",
         "-0.0004675735137396",
         "-0.0083525606374236",
         "-0.0047203208458317",
         "-0.0002345358934032",
         "0.0056603629634064",
         "0.0049774973545766",
         "-0.0021286516614683",
         "-0.0037700427109477",
         "0.0076885153648309",
         "0.0060846711753157",
         "0.0057852477631346",
         "0.0016455861186227",
         "0.0019440026493882",
         "0.001629153045355",
         "0.0164558611862277",
         "0.0388800529877648",
         "0.0488745913606505",
         "44.729371070708645",
         "-0.0002829471434768",
         "0.0003654214250887",
         "-0.0091735787877978",
         "0.0065709376563893",
         "0.0106031736152272",
         "0.007384767507389",
         "-0.0087312664736241",
         "0.0039844512084357",
         "0.0041790862581623",
         "0.0730301325045266",
         "0.0070967520436933",
         "0.0051698089325677",
         "-0.0053757051082528",
         "-0.0073085530826206",
         "0.0119498639172681",
         "0.0097116490729938",
         "0.0107079304517807",
         "4.083000183105469",
         "4.085999965667725",
         "4.249000072479248"
        ],
        [
         "2004-01-14 00:00:00",
         "-0.0047203208458317",
         "-0.0105510063201985",
         "3.986000061035156",
         "0.008350872283781",
         "-0.0715078076529928",
         "0.0060811206885245",
         "0.0020331017776289",
         "-0.0315390512818324",
         "-0.0060989342256327",
         "-0.0002345358934032",
         "0.0056603629634064",
         "0.0049774973545766",
         "-0.0021286516614683",
         "0.0078297080588691",
         "0.00590356469669",
         "0.0058977705790362",
         "0.0014613884564481",
         "0.0011806395793529",
         "0.0014552966165821",
         "0.0146138845644811",
         "0.0236127915870599",
         "0.0436588984974641",
         "47.25815115483868",
         "-0.0007348581699757",
         "0.0001453655060758",
         "0.0035290394908482",
         "-0.0091735787877978",
         "0.0065709376563893",
         "-0.0058297419394889",
         "0.007384767507389",
         "-0.0087312664736241",
         "0.072532773058167",
         "0.0041790862581623",
         "0.0730301325045266",
         "-0.0004675735137396",
         "0.0051698089325677",
         "-0.0053757051082528",
         "-0.0083525606374236",
         "0.0119498639172681",
         "0.0097116490729938",
         "4.0279998779296875",
         "4.083000183105469",
         "4.085999965667725"
        ],
        [
         "2004-01-15 00:00:00",
         "-0.0315390512818324",
         "-0.0039566750210084",
         "3.9709999561309814",
         "0.0024678593764206",
         "-0.0710447510676597",
         "0.0061606275347805",
         "-0.030724677486696",
         "-0.0041625409276669",
         "-0.0047203208458317",
         "-0.0060989342256327",
         "-0.0002345358934032",
         "0.0056603629634064",
         "0.0049774973545766",
         "0.0130773814304934",
         "0.009372076548075",
         "0.0084253284496538",
         "-0.0016925166717351",
         "-0.0002021374867391",
         "0.0004535126188806",
         "-0.0169251667173512",
         "-0.004042749734783",
         "0.0136053785664181",
         "36.03204564732906",
         "-0.0032199309671704",
         "-0.0005276937885733",
         "-0.0105510063201985",
         "0.0035290394908482",
         "-0.0091735787877978",
         "0.008350872283781",
         "-0.0058297419394889",
         "0.007384767507389",
         "-0.0715078076529928",
         "0.072532773058167",
         "0.0041790862581623",
         "0.0060811206885245",
         "-0.0004675735137396",
         "0.0051698089325677",
         "0.0020331017776289",
         "-0.0083525606374236",
         "0.0119498639172681",
         "3.986000061035156",
         "4.0279998779296875",
         "4.083000183105469"
        ],
        [
         "2004-01-16 00:00:00",
         "-0.0041625409276669",
         "-0.0161050762616106",
         "4.013999938964844",
         "0.0039549857831444",
         "-0.0359897432207456",
         "0.013516703227121",
         "0.0487440530817884",
         "0.0",
         "-0.0315390512818324",
         "-0.0047203208458317",
         "-0.0060989342256327",
         "-0.0002345358934032",
         "0.0056603629634064",
         "0.0130837680528664",
         "0.009395072840499",
         "0.0083519746481742",
         "-0.0021087707645018",
         "-0.000264067931356",
         "5.854122013076969e-05",
         "-0.0210877076450181",
         "-0.0052813586271201",
         "0.001756236603923",
         "46.190290575577464",
         "-0.0029463497860969",
         "-0.0010114249880781",
         "-0.0039566750210084",
         "-0.0105510063201985",
         "0.0035290394908482",
         "0.0024678593764206",
         "0.008350872283781",
         "-0.0058297419394889",
         "-0.0710447510676597",
         "-0.0715078076529928",
         "0.072532773058167",
         "0.0061606275347805",
         "0.0060811206885245",
         "-0.0004675735137396",
         "-0.030724677486696",
         "0.0020331017776289",
         "-0.0083525606374236",
         "3.9709999561309814",
         "3.986000061035156",
         "4.0279998779296875"
        ],
        [
         "2004-01-19 00:00:00",
         "0.0",
         "-0.0035455987557183",
         "4.013999938964844",
         "0.0",
         "0.0",
         "-0.0007978991467653",
         "0.0",
         "0.0147528886646448",
         "-0.0041625409276669",
         "-0.0315390512818324",
         "-0.0047203208458317",
         "-0.0060989342256327",
         "-0.0002345358934032",
         "0.0103847925946379",
         "0.0093555023212276",
         "0.0083515769036345",
         "-0.0042016217228799",
         "-0.0004351326741126",
         "4.2136019176446365e-05",
         "-0.0420162172287999",
         "-0.0087026534822531",
         "0.0012640805752933",
         "48.15731166964136",
         "-0.0023663743732358",
         "-0.0012824148651096",
         "-0.0161050762616106",
         "-0.0039566750210084",
         "-0.0105510063201985",
         "0.0039549857831444",
         "0.0024678593764206",
         "0.008350872283781",
         "-0.0359897432207456",
         "-0.0710447510676597",
         "-0.0715078076529928",
         "0.013516703227121",
         "0.0061606275347805",
         "0.0060811206885245",
         "0.0487440530817884",
         "-0.030724677486696",
         "0.0020331017776289",
         "4.013999938964844",
         "3.9709999561309814",
         "3.986000061035156"
        ]
       ],
       "shape": {
        "columns": 43,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold</th>\n",
       "      <th>eurusd</th>\n",
       "      <th>treasury_10y</th>\n",
       "      <th>spy</th>\n",
       "      <th>vix</th>\n",
       "      <th>dxy</th>\n",
       "      <th>oil</th>\n",
       "      <th>target</th>\n",
       "      <th>gold_lag1</th>\n",
       "      <th>gold_lag2</th>\n",
       "      <th>...</th>\n",
       "      <th>vix_lag3</th>\n",
       "      <th>dxy_lag1</th>\n",
       "      <th>dxy_lag2</th>\n",
       "      <th>dxy_lag3</th>\n",
       "      <th>oil_lag1</th>\n",
       "      <th>oil_lag2</th>\n",
       "      <th>oil_lag3</th>\n",
       "      <th>treasury_10y_lag1</th>\n",
       "      <th>treasury_10y_lag2</th>\n",
       "      <th>treasury_10y_lag3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-13</th>\n",
       "      <td>-0.006099</td>\n",
       "      <td>0.003529</td>\n",
       "      <td>4.028</td>\n",
       "      <td>-0.005830</td>\n",
       "      <td>0.072533</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>-0.008353</td>\n",
       "      <td>-0.004720</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007097</td>\n",
       "      <td>0.005170</td>\n",
       "      <td>-0.005376</td>\n",
       "      <td>-0.007309</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.009712</td>\n",
       "      <td>0.010708</td>\n",
       "      <td>4.083</td>\n",
       "      <td>4.086</td>\n",
       "      <td>4.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-14</th>\n",
       "      <td>-0.004720</td>\n",
       "      <td>-0.010551</td>\n",
       "      <td>3.986</td>\n",
       "      <td>0.008351</td>\n",
       "      <td>-0.071508</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>-0.031539</td>\n",
       "      <td>-0.006099</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073030</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>0.005170</td>\n",
       "      <td>-0.005376</td>\n",
       "      <td>-0.008353</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.009712</td>\n",
       "      <td>4.028</td>\n",
       "      <td>4.083</td>\n",
       "      <td>4.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-15</th>\n",
       "      <td>-0.031539</td>\n",
       "      <td>-0.003957</td>\n",
       "      <td>3.971</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>-0.071045</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>-0.030725</td>\n",
       "      <td>-0.004163</td>\n",
       "      <td>-0.004720</td>\n",
       "      <td>-0.006099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>0.005170</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>-0.008353</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>3.986</td>\n",
       "      <td>4.028</td>\n",
       "      <td>4.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-16</th>\n",
       "      <td>-0.004163</td>\n",
       "      <td>-0.016105</td>\n",
       "      <td>4.014</td>\n",
       "      <td>0.003955</td>\n",
       "      <td>-0.035990</td>\n",
       "      <td>0.013517</td>\n",
       "      <td>0.048744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.031539</td>\n",
       "      <td>-0.004720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072533</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>-0.030725</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>-0.008353</td>\n",
       "      <td>3.971</td>\n",
       "      <td>3.986</td>\n",
       "      <td>4.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003546</td>\n",
       "      <td>4.014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014753</td>\n",
       "      <td>-0.004163</td>\n",
       "      <td>-0.031539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071508</td>\n",
       "      <td>0.013517</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.048744</td>\n",
       "      <td>-0.030725</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>4.014</td>\n",
       "      <td>3.971</td>\n",
       "      <td>3.986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                gold    eurusd  treasury_10y       spy       vix       dxy  \\\n",
       "Date                                                                         \n",
       "2004-01-13 -0.006099  0.003529         4.028 -0.005830  0.072533 -0.000468   \n",
       "2004-01-14 -0.004720 -0.010551         3.986  0.008351 -0.071508  0.006081   \n",
       "2004-01-15 -0.031539 -0.003957         3.971  0.002468 -0.071045  0.006161   \n",
       "2004-01-16 -0.004163 -0.016105         4.014  0.003955 -0.035990  0.013517   \n",
       "2004-01-19  0.000000 -0.003546         4.014  0.000000  0.000000 -0.000798   \n",
       "\n",
       "                 oil    target  gold_lag1  gold_lag2  ...  vix_lag3  dxy_lag1  \\\n",
       "Date                                                  ...                       \n",
       "2004-01-13 -0.008353 -0.004720  -0.000235   0.005660  ...  0.007097  0.005170   \n",
       "2004-01-14  0.002033 -0.031539  -0.006099  -0.000235  ...  0.073030 -0.000468   \n",
       "2004-01-15 -0.030725 -0.004163  -0.004720  -0.006099  ...  0.004179  0.006081   \n",
       "2004-01-16  0.048744  0.000000  -0.031539  -0.004720  ...  0.072533  0.006161   \n",
       "2004-01-19  0.000000  0.014753  -0.004163  -0.031539  ... -0.071508  0.013517   \n",
       "\n",
       "            dxy_lag2  dxy_lag3  oil_lag1  oil_lag2  oil_lag3  \\\n",
       "Date                                                           \n",
       "2004-01-13 -0.005376 -0.007309  0.011950  0.009712  0.010708   \n",
       "2004-01-14  0.005170 -0.005376 -0.008353  0.011950  0.009712   \n",
       "2004-01-15 -0.000468  0.005170  0.002033 -0.008353  0.011950   \n",
       "2004-01-16  0.006081 -0.000468 -0.030725  0.002033 -0.008353   \n",
       "2004-01-19  0.006161  0.006081  0.048744 -0.030725  0.002033   \n",
       "\n",
       "            treasury_10y_lag1  treasury_10y_lag2  treasury_10y_lag3  \n",
       "Date                                                                 \n",
       "2004-01-13              4.083              4.086              4.249  \n",
       "2004-01-14              4.028              4.083              4.086  \n",
       "2004-01-15              3.986              4.028              4.083  \n",
       "2004-01-16              3.971              3.986              4.028  \n",
       "2004-01-19              4.014              3.971              3.986  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/erion/Desktop/MSCF2/ADA/Capstone-Project/data/processed/modeling_dataset.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5d874f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 3123\n",
      "Test samples: 261\n"
     ]
    }
   ],
   "source": [
    "train = df.loc[:'2015-12-31'].copy()\n",
    "test  = df.loc['2016-01-01':'2016-12-31'].copy()\n",
    "\n",
    "X_train = train.drop(columns=['target'])\n",
    "y_train = train['target']\n",
    "\n",
    "X_test = test.drop(columns=['target'])\n",
    "y_test = test['target']\n",
    "\n",
    "print(\"Train samples:\", len(X_train))\n",
    "print(\"Test samples:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b625518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dcc4c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/goldcapstone/lib/python3.10/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,752</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,752\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,865</span> (19.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,865\u001b[0m (19.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,865</span> (19.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,865\u001b[0m (19.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output: predicted return\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse'\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc7b9c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0751 - val_loss: 0.0260\n",
      "Epoch 2/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0218 - val_loss: 0.0174\n",
      "Epoch 3/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - loss: 0.0138 - val_loss: 0.0145\n",
      "Epoch 4/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0123\n",
      "Epoch 5/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - loss: 0.0073 - val_loss: 0.0105\n",
      "Epoch 6/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0059 - val_loss: 0.0096\n",
      "Epoch 7/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 0.0047 - val_loss: 0.0087\n",
      "Epoch 8/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0040 - val_loss: 0.0082\n",
      "Epoch 9/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 0.0032 - val_loss: 0.0077\n",
      "Epoch 10/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0073\n",
      "Epoch 11/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - val_loss: 0.0069\n",
      "Epoch 12/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - val_loss: 0.0066\n",
      "Epoch 13/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 0.0021 - val_loss: 0.0062\n",
      "Epoch 14/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 15/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 16/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 17/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 18/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 19/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 20/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 21/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 22/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 23/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 24/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 25/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 26/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 27/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 28/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 9.8513e-04 - val_loss: 0.0031\n",
      "Epoch 29/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 7.6384e-04 - val_loss: 0.0031\n",
      "Epoch 30/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 9.9340e-04 - val_loss: 0.0030\n",
      "Epoch 31/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 8.9531e-04 - val_loss: 0.0029\n",
      "Epoch 32/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 6.8750e-04 - val_loss: 0.0027\n",
      "Epoch 33/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2652e-04 - val_loss: 0.0026\n",
      "Epoch 34/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 4.9632e-04 - val_loss: 0.0026\n",
      "Epoch 35/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 4.3307e-04 - val_loss: 0.0024\n",
      "Epoch 36/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 4.6671e-04 - val_loss: 0.0024\n",
      "Epoch 37/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 4.0320e-04 - val_loss: 0.0024\n",
      "Epoch 38/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 4.2753e-04 - val_loss: 0.0023\n",
      "Epoch 39/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 3.4562e-04 - val_loss: 0.0022\n",
      "Epoch 40/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 3.8042e-04 - val_loss: 0.0023\n",
      "Epoch 41/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 5.2906e-04 - val_loss: 0.0021\n",
      "Epoch 42/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5394e-04 - val_loss: 0.0021\n",
      "Epoch 43/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 4.4047e-04 - val_loss: 0.0019\n",
      "Epoch 44/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2717e-04 - val_loss: 0.0019\n",
      "Epoch 45/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 3.6611e-04 - val_loss: 0.0020\n",
      "Epoch 46/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 4.2957e-04 - val_loss: 0.0018\n",
      "Epoch 47/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 4.7740e-04 - val_loss: 0.0018\n",
      "Epoch 48/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 6.7655e-04 - val_loss: 0.0017\n",
      "Epoch 49/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 4.7720e-04 - val_loss: 0.0016\n",
      "Epoch 50/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 4.1492e-04 - val_loss: 0.0017\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0c9f061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "MLP Performance\n",
      "---------------------------\n",
      "RMSE: 0.037823\n",
      "MAE:  0.028355\n",
      "Directional Accuracy: 54.02%\n"
     ]
    }
   ],
   "source": [
    "mlp_pred = model.predict(X_test_scaled).flatten()\n",
    "\n",
    "rmse_mlp = np.sqrt(mean_squared_error(y_test, mlp_pred))\n",
    "mae_mlp = mean_absolute_error(y_test, mlp_pred)\n",
    "dir_acc_mlp = (np.sign(mlp_pred) == np.sign(y_test)).mean() * 100\n",
    "\n",
    "print(\"MLP Performance\")\n",
    "print(\"---------------------------\")\n",
    "print(f\"RMSE: {rmse_mlp:.6f}\")\n",
    "print(f\"MAE:  {mae_mlp:.6f}\")\n",
    "print(f\"Directional Accuracy: {dir_acc_mlp:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed6972a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM train shape: (3118, 5, 42)\n",
      "LSTM test shape: (256, 5, 42)\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(X, y, timesteps=5):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - timesteps):\n",
    "        X_seq.append(X[i:i+timesteps])\n",
    "        y_seq.append(y[i+timesteps])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Convert scaled features to sequences\n",
    "timesteps = 5\n",
    "\n",
    "X_train_lstm, y_train_lstm = create_sequences(X_train_scaled, y_train.values, timesteps)\n",
    "X_test_lstm, y_test_lstm   = create_sequences(X_test_scaled, y_test.values, timesteps)\n",
    "\n",
    "print(\"LSTM train shape:\", X_train_lstm.shape)\n",
    "print(\"LSTM test shape:\", X_test_lstm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31d59e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/goldcapstone/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">27,392</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m27,392\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,505</span> (115.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,505\u001b[0m (115.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,505</span> (115.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,505\u001b[0m (115.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "lstm_model = Sequential([\n",
    "    LSTM(64, activation='tanh', return_sequences=False, input_shape=(timesteps, X_train_lstm.shape[2])),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "lstm_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse'\n",
    ")\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bb6538c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 2/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 3/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9052e-04 - val_loss: 0.0013\n",
      "Epoch 4/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9982e-04 - val_loss: 0.0012\n",
      "Epoch 5/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8816e-04 - val_loss: 0.0010\n",
      "Epoch 6/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1705e-04 - val_loss: 9.5258e-04\n",
      "Epoch 7/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.6179e-04 - val_loss: 9.3343e-04\n",
      "Epoch 8/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4030e-04 - val_loss: 9.0205e-04\n",
      "Epoch 9/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3381e-04 - val_loss: 8.5454e-04\n",
      "Epoch 10/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9690e-04 - val_loss: 9.0340e-04\n",
      "Epoch 11/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6536e-04 - val_loss: 7.6908e-04\n",
      "Epoch 12/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5979e-04 - val_loss: 8.0911e-04\n",
      "Epoch 13/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6443e-04 - val_loss: 7.6709e-04\n",
      "Epoch 14/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3684e-04 - val_loss: 7.3097e-04\n",
      "Epoch 15/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3293e-04 - val_loss: 7.2789e-04\n",
      "Epoch 16/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1001e-04 - val_loss: 7.1702e-04\n",
      "Epoch 17/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0021e-04 - val_loss: 6.8919e-04\n",
      "Epoch 18/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0328e-04 - val_loss: 7.1662e-04\n",
      "Epoch 19/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0680e-04 - val_loss: 6.6507e-04\n",
      "Epoch 20/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2641e-04 - val_loss: 6.8346e-04\n",
      "Epoch 21/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5139e-04 - val_loss: 6.4271e-04\n",
      "Epoch 22/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5676e-04 - val_loss: 6.0256e-04\n",
      "Epoch 23/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2377e-04 - val_loss: 5.9967e-04\n",
      "Epoch 24/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0766e-05 - val_loss: 5.8050e-04\n",
      "Epoch 25/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4555e-05 - val_loss: 5.7769e-04\n",
      "Epoch 26/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5245e-05 - val_loss: 6.3573e-04\n",
      "Epoch 27/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2258e-05 - val_loss: 5.9537e-04\n",
      "Epoch 28/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8254e-05 - val_loss: 5.6109e-04\n",
      "Epoch 29/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7768e-05 - val_loss: 5.5001e-04\n",
      "Epoch 30/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6501e-05 - val_loss: 5.5952e-04\n",
      "Epoch 31/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0789e-05 - val_loss: 5.8998e-04\n",
      "Epoch 32/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9426e-05 - val_loss: 5.5722e-04\n",
      "Epoch 33/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3677e-05 - val_loss: 5.7282e-04\n",
      "Epoch 34/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9576e-05 - val_loss: 5.6663e-04\n",
      "Epoch 35/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2545e-05 - val_loss: 5.4719e-04\n",
      "Epoch 36/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6784e-05 - val_loss: 5.5950e-04\n",
      "Epoch 37/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8418e-05 - val_loss: 5.1213e-04\n",
      "Epoch 38/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5139e-05 - val_loss: 5.1711e-04\n",
      "Epoch 39/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1785e-05 - val_loss: 4.9571e-04\n",
      "Epoch 40/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9893e-05 - val_loss: 5.6117e-04\n"
     ]
    }
   ],
   "source": [
    "history_lstm = lstm_model.fit(\n",
    "    X_train_lstm, y_train_lstm,\n",
    "    validation_split=0.2,\n",
    "    epochs=40,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5af1e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "LSTM Performance\n",
      "---------------------------\n",
      "RMSE: 0.024299\n",
      "MAE:  0.018148\n",
      "Directional Accuracy: 48.05%\n"
     ]
    }
   ],
   "source": [
    "lstm_pred = lstm_model.predict(X_test_lstm).flatten()\n",
    "\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_test_lstm, lstm_pred))\n",
    "mae_lstm = mean_absolute_error(y_test_lstm, lstm_pred)\n",
    "dir_acc_lstm = (np.sign(lstm_pred) == np.sign(y_test_lstm)).mean() * 100\n",
    "\n",
    "print(\"LSTM Performance\")\n",
    "print(\"---------------------------\")\n",
    "print(f\"RMSE: {rmse_lstm:.6f}\")\n",
    "print(f\"MAE:  {mae_lstm:.6f}\")\n",
    "print(f\"Directional Accuracy: {dir_acc_lstm:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec4209d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/goldcapstone/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,736</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m20,736\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,849</span> (89.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,849\u001b[0m (89.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,849</span> (89.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,849\u001b[0m (89.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "gru_model = Sequential([\n",
    "    GRU(64, activation='tanh', return_sequences=False, input_shape=(timesteps, X_train_lstm.shape[2])),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "gru_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse'\n",
    ")\n",
    "\n",
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8efdce6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.0081\n",
      "Epoch 2/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 3/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 4/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 5/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 6/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9295e-04 - val_loss: 0.0033\n",
      "Epoch 7/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2359e-04 - val_loss: 0.0030\n",
      "Epoch 8/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2509e-04 - val_loss: 0.0026\n",
      "Epoch 9/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6525e-04 - val_loss: 0.0024\n",
      "Epoch 10/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9071e-04 - val_loss: 0.0023\n",
      "Epoch 11/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4311e-04 - val_loss: 0.0021\n",
      "Epoch 12/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8933e-04 - val_loss: 0.0020\n",
      "Epoch 13/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7049e-04 - val_loss: 0.0019\n",
      "Epoch 14/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5449e-04 - val_loss: 0.0020\n",
      "Epoch 15/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3133e-04 - val_loss: 0.0018\n",
      "Epoch 16/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4015e-04 - val_loss: 0.0018\n",
      "Epoch 17/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3571e-04 - val_loss: 0.0018\n",
      "Epoch 18/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8698e-04 - val_loss: 0.0016\n",
      "Epoch 19/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7413e-04 - val_loss: 0.0015\n",
      "Epoch 20/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3915e-04 - val_loss: 0.0015\n",
      "Epoch 21/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1901e-04 - val_loss: 0.0015\n",
      "Epoch 22/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1195e-04 - val_loss: 0.0015\n",
      "Epoch 23/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2030e-04 - val_loss: 0.0016\n",
      "Epoch 24/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8394e-04 - val_loss: 0.0014\n",
      "Epoch 25/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6534e-04 - val_loss: 0.0014\n",
      "Epoch 26/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6074e-04 - val_loss: 0.0013\n",
      "Epoch 27/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4547e-04 - val_loss: 0.0013\n",
      "Epoch 28/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4550e-04 - val_loss: 0.0013\n",
      "Epoch 29/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3682e-04 - val_loss: 0.0013\n",
      "Epoch 30/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2160e-04 - val_loss: 0.0012\n",
      "Epoch 31/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1714e-04 - val_loss: 0.0012\n",
      "Epoch 32/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3068e-04 - val_loss: 0.0012\n",
      "Epoch 33/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2612e-04 - val_loss: 0.0012\n",
      "Epoch 34/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3988e-04 - val_loss: 0.0011\n",
      "Epoch 35/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4521e-04 - val_loss: 0.0011\n",
      "Epoch 36/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4256e-04 - val_loss: 0.0011\n",
      "Epoch 37/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2281e-04 - val_loss: 0.0011\n",
      "Epoch 38/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0697e-04 - val_loss: 0.0011\n",
      "Epoch 39/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4405e-05 - val_loss: 0.0010\n",
      "Epoch 40/40\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9362e-05 - val_loss: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history_gru = gru_model.fit(\n",
    "    X_train_lstm, y_train_lstm,\n",
    "    validation_split=0.2,\n",
    "    epochs=40,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21fbb0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "GRU Performance\n",
      "---------------------------\n",
      "RMSE: 0.034939\n",
      "MAE:  0.026941\n",
      "Directional Accuracy: 49.22%\n"
     ]
    }
   ],
   "source": [
    "gru_pred = gru_model.predict(X_test_lstm).flatten()\n",
    "\n",
    "rmse_gru = np.sqrt(mean_squared_error(y_test_lstm, gru_pred))\n",
    "mae_gru = mean_absolute_error(y_test_lstm, gru_pred)\n",
    "dir_acc_gru = (np.sign(gru_pred) == np.sign(y_test_lstm)).mean() * 100\n",
    "\n",
    "print(\"GRU Performance\")\n",
    "print(\"---------------------------\")\n",
    "print(f\"RMSE: {rmse_gru:.6f}\")\n",
    "print(f\"MAE:  {mae_gru:.6f}\")\n",
    "print(f\"Directional Accuracy: {dir_acc_gru:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e1d43dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEEP LEARNING MODEL COMPARISON (2016 Test Set)\n",
      "  Model      RMSE       MAE  Directional Accuracy (%)\n",
      "0   MLP  0.037823  0.028355                 54.022989\n",
      "1  LSTM  0.024299  0.018148                 48.046875\n",
      "2   GRU  0.034939  0.026941                 49.218750\n"
     ]
    }
   ],
   "source": [
    "results_dl = pd.DataFrame({\n",
    "    'Model': ['MLP', 'LSTM', 'GRU'],\n",
    "    'RMSE': [rmse_mlp, rmse_lstm, rmse_gru],\n",
    "    'MAE': [mae_mlp, mae_lstm, mae_gru],\n",
    "    'Directional Accuracy (%)': [dir_acc_mlp, dir_acc_lstm, dir_acc_gru]\n",
    "})\n",
    "\n",
    "print(\"\\nDEEP LEARNING MODEL COMPARISON (2016 Test Set)\")\n",
    "print(results_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goldcapstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
